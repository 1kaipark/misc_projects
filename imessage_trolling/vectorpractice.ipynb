{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T03:50:32.181007Z",
     "start_time": "2024-05-16T03:50:32.169533Z"
    }
   },
   "outputs": [],
   "source": [
    "#here is a program to test vector search. It is currently set up to read in a .txt file of the 1000 most common english words. Then, it will perform sentiment analysis on \n",
    "#each of these words. It assigns each word 4 coordinates based on this sentiment analysis and assigns each word a position within an array. After forming the array,\n",
    "#the user is prompted to enter a word. The program performs sentiment analysis on this word then finds its 5 nearest neighbors using a KDTree.\n",
    "\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "\n",
    "#set up sentiment analysis\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "#vectorize a long list of words. Returns dict where key = word and value = coordinates.\n",
    "def vectorize(list):\n",
    "    vector_dict = {}\n",
    "    for item in list:\n",
    "        score = sia.polarity_scores(item)\n",
    "        positive_score = score['pos']\n",
    "        negative_score = score['neg']\n",
    "        neutral_score = score['neu']\n",
    "        compound_score = score['compound']\n",
    "        vector_list = [positive_score, neutral_score, negative_score, compound_score]\n",
    "        vector_dict[item] = vector_list\n",
    "    return(vector_dict)\n",
    "\n",
    "#vectorize a single word (user input). Returns list of coordinates.\n",
    "def sent_analysis(str):\n",
    "    score = sia.polarity_scores(str)\n",
    "    positive_score = score['pos']\n",
    "    negative_score = score['neg']\n",
    "    neutral_score = score['neu']\n",
    "    compound_score = score['compound']\n",
    "    vector_list = [positive_score, neutral_score, negative_score, compound_score]\n",
    "    return(vector_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T03:50:36.043405Z",
     "start_time": "2024-05-16T03:50:35.697719Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KDTree\n",
    "\n",
    "#specify filename\n",
    "file_name = \"common_words.txt\"\n",
    "\n",
    "#open file, read contents, put them in a list\n",
    "with open(file_name, 'r') as file:\n",
    "    file_contents = []\n",
    "    for line in file:\n",
    "        file_contents.append(line.strip())\n",
    "\n",
    "#vectorize the list of items in the file\n",
    "element_dict = vectorize(file_contents)\n",
    "\n",
    "#this list contains only the keys (i.e. the words themselves)\n",
    "words = list(element_dict.keys())\n",
    "\n",
    "#this array contains only the values (i.e. the coordinates)\n",
    "vectors = np.array(list(element_dict.values()))\n",
    "\n",
    "#create a KDTree based on the array of vectors\n",
    "tree = KDTree(vectors, leaf_size=40)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T03:53:08.355228Z",
     "start_time": "2024-05-16T03:53:07.772572Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the coordinates of odd are [[ 0.      0.      1.     -0.3182]]\n",
      "The 5 nearest words to odd and their distances:\n",
      "1: lost (Distance: 0.0)\n",
      "2: fire (Distance: 0.02180000000000004)\n",
      "3: gun (Distance: 0.02180000000000004)\n",
      "4: stop (Distance: 0.022199999999999998)\n",
      "5: no (Distance: 0.022199999999999998)\n"
     ]
    }
   ],
   "source": [
    "#prompt user for a new word\n",
    "new_word = input(\"New Word: \")\n",
    "\n",
    "#perform sentiment analysis on new word to get coordinates\n",
    "new_word_coordinates = np.array([sent_analysis(new_word)])\n",
    "print(f\"the coordinates of {new_word} are {new_word_coordinates}\")\n",
    "\n",
    "\n",
    "# Find the index of the nearest 5 vectors\n",
    "distances, indices = tree.query(new_word_coordinates, k=5)\n",
    "nearest_word_indices = indices[0]\n",
    "nearest_words = [words[i] for i in nearest_word_indices]\n",
    "\n",
    "#print the nearest 5 vectors\n",
    "print(f\"The 5 nearest words to {new_word} and their distances:\")\n",
    "for i, word in enumerate(nearest_words):\n",
    "    print(f\"{i+1}: {word} (Distance: {distances[0][i]})\")"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[55], line 26\u001B[0m\n\u001B[1;32m     24\u001B[0m msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(nearest_words)\n\u001B[1;32m     25\u001B[0m send_message(NUMBER, stacker(SPACER\u001B[38;5;241m.\u001B[39mjoin([c \u001B[38;5;28;01mfor\u001B[39;00m c \u001B[38;5;129;01min\u001B[39;00m msg]), \u001B[38;5;241m*\u001B[39mSTACK))\n\u001B[0;32m---> 26\u001B[0m time\u001B[38;5;241m.\u001B[39msleep(INTERVAL)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "import time\n",
    "from imsg import *\n",
    "\n",
    "NUMBER = '2103050549'\n",
    "SPACER = ''\n",
    "STACK = [convert]\n",
    "REPEATS = 6\n",
    "INTERVAL = 3600\n",
    "\n",
    "bigwords = []\n",
    "for word in file_contents:\n",
    "    if sent_analysis(word)[2] > 0.5:\n",
    "        bigwords.append(word)\n",
    "\n",
    "for i in range(REPEATS):\n",
    "    startword = random.choice(bigwords)\n",
    "    startword_coords = np.array([sent_analysis(startword)])\n",
    "    dist, idx = tree.query(startword_coords, k=47)\n",
    "    nearest_word_indices = idx[0]\n",
    "    nearest_words = [words[i] for i in nearest_word_indices]\n",
    "    msg = ' '.join(nearest_words)\n",
    "    send_message(NUMBER, stacker(SPACER.join([c for c in msg]), *STACK))\n",
    "    time.sleep(INTERVAL)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-16T04:13:34.441081Z",
     "start_time": "2024-05-16T04:00:22.438807Z"
    }
   },
   "execution_count": 55
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-16T03:58:38.669650Z",
     "start_time": "2024-05-16T03:58:38.655417Z"
    }
   },
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "['like',\n 'good',\n 'great',\n 'help',\n 'well',\n 'play',\n 'hand',\n 'kind',\n 'ease',\n 'care',\n 'friend',\n 'sure',\n 'ready',\n 'best',\n 'better',\n 'true',\n 'interest',\n 'love',\n 'certain',\n 'beauty',\n 'free',\n 'strong',\n 'special',\n 'clear',\n 'laugh',\n 'yes',\n 'grand',\n 'energy',\n 'wish',\n 'joy',\n 'fun',\n 'bright',\n 'happy',\n 'hope',\n 'safe',\n 'value',\n 'excite',\n 'natural',\n 'surprise',\n 'cool',\n 'smile',\n 'join',\n 'clean',\n 'fit',\n 'fair',\n 'save',\n 'gentle',\n 'please',\n 'protect',\n 'party',\n 'agree',\n 'rich',\n 'create',\n 'fresh',\n 'success',\n 'pretty',\n 'solution',\n 'thank',\n 'huge',\n 'win',\n 'favor',\n 'glad',\n 'original',\n 'share',\n 'dear',\n 'support']"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigwords\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-16T03:58:41.583534Z",
     "start_time": "2024-05-16T03:58:41.580219Z"
    }
   },
   "execution_count": 47
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[0.0, 1.0, 0.0, 0.0]"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_analysis('acetal')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-16T04:13:40.867614Z",
     "start_time": "2024-05-16T04:13:40.863834Z"
    }
   },
   "execution_count": 56
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
